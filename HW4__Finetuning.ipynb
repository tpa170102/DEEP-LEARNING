{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xh4Y4j1yiDXp"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import CIFAR10, MNIST, FashionMNIST\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.001\n",
        "batch_size = 64\n",
        "num_epochs = 5\n",
        "momentum = 0.9"
      ],
      "metadata": {
        "id": "66Z6WLNIkDnc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Augmentation"
      ],
      "metadata": {
        "id": "H_HuhJoTkHQU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((28, 28)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    #transforms.CenterCrop(28),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,)), ])  # Normalize to [-1, 1]\n",
        "\n",
        "# Load data and Apply the transformations to the dataset\n",
        "train_dataset = FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = FashionMNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "8n3Iq2FlkDj7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Finetuning"
      ],
      "metadata": {
        "id": "iPGgDchTkNjK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "9keHP5OYkDhb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MiniVGG(nn.Module):\n",
        "    def __init__(self,):\n",
        "        super(MiniVGG, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(1, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size= 3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(128, 128, kernel_size= 3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            nn.Conv2d(128, 256, kernel_size= 3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size= 3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "        self.classifier = nn.Linear(256*3*3, 10)\n",
        "        nn.init.normal_(self.classifier.weight, 0, 0.01)\n",
        "        nn.init.constant_(self.classifier.bias, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "Ev_jvfSzkDe_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, optimizer, train_loader):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "        print(f\"Epoch {epoch+1} - Loss: {running_loss / len(train_loader)}\")\n",
        "\n",
        "\n",
        "# Evaluation\n",
        "def evaluate_model(model, test_loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    accuracy = 100 * correct / total\n",
        "    print(\"Accuracy on the test set:\", accuracy)"
      ],
      "metadata": {
        "id": "vHRjqygZkWtW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CIFAR-10"
      ],
      "metadata": {
        "id": "OcsG8tnUmnL2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "O_tdgfMGkDcI",
        "outputId": "d76dd83a-d125-4c29-cc86-31f45a2913e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-95ad69b4-d7cc-4bf0-bb50-414b52fb9915\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-95ad69b4-d7cc-4bf0-bb50-414b52fb9915\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving cifar10_mini_vgg.pth to cifar10_mini_vgg.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"cifar10_mini_vgg.pth\"\n",
        "model_cifar = MiniVGG()\n",
        "\n",
        "#Load model's weight\n",
        "#model_cifar = torch.load(path)#, map_location=torch.device(device))\n",
        "model_cifar.load_state_dict(torch.load(path,map_location=torch.device(device)), strict= False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGhIKljlkDZr",
        "outputId": "2f87d246-4599-45fe-85e6-097816cfd6f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Freeze all layers except the last layer\n",
        "for param in model_cifar.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Set the requires_grad attribute of the parameters in the last layer to True\n",
        "for param in model_cifar.classifier.parameters():\n",
        "    param.requires_grad = True"
      ],
      "metadata": {
        "id": "DaRn2NrckDXM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define loss function and optimizer\n",
        "model_cifar.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer_cifar = optim.SGD(model_cifar.parameters(), lr=learning_rate, momentum=momentum)\n",
        "\n",
        "train_model(model_cifar, optimizer_cifar, train_loader)\n",
        "\n",
        "accuracy_cifar = evaluate_model(model_cifar, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qnxcgY0skDU6",
        "outputId": "af1566b9-3d17-479f-8156-d510d96272b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 - Loss: 0.9976865335631726\n",
            "Epoch 2 - Loss: 0.4918440717941662\n",
            "Epoch 3 - Loss: 0.42290419626083453\n",
            "Epoch 4 - Loss: 0.38590323954407596\n",
            "Epoch 5 - Loss: 0.37005098025078204\n",
            "Accuracy on the test set: 87.18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MNIST"
      ],
      "metadata": {
        "id": "uSr_5bSzmvN6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "boswvtG-kDSa",
        "outputId": "5a719928-bf4f-4241-f399-cf571ffef572"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e43d9448-ad04-4865-a04a-28c016f1b242\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-e43d9448-ad04-4865-a04a-28c016f1b242\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving mnist_mini_vgg.pth to mnist_mini_vgg.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"mnist_mini_vgg.pth\"\n",
        "model_mnist = MiniVGG()\n",
        "\n",
        "model_mnist.load_state_dict(torch.load(path,map_location=torch.device(device)), strict= False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RN56rhzGkDP-",
        "outputId": "b3749ea0-72d2-48e3-cdef-62323b37b755"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Freeze all layers except the last layer\n",
        "for param in model_mnist.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Set the requires_grad attribute of the parameters in the last layer to True\n",
        "for param in model_mnist.classifier.parameters():\n",
        "    param.requires_grad = True"
      ],
      "metadata": {
        "id": "7icmH1_ckDNR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define loss function and optimizer\n",
        "model_mnist.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer_mnist = optim.SGD(model_mnist.parameters(), lr=learning_rate,momentum=momentum)\n",
        "\n",
        "train_model(model_mnist, optimizer_mnist, train_loader)\n",
        "\n",
        "accuracy_mnist = evaluate_model(model_mnist, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3MNd-1RNkDKh",
        "outputId": "89dd54fd-c062-49d4-f0d4-7981045127b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 - Loss: 0.9410194106765394\n",
            "Epoch 2 - Loss: 0.5633330147371871\n",
            "Epoch 3 - Loss: 0.514084163457473\n",
            "Epoch 4 - Loss: 0.4874532163492652\n",
            "Epoch 5 - Loss: 0.4722584866003187\n",
            "Accuracy on the test set: 83.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train MiniVGG on FashionMnist from scratch"
      ],
      "metadata": {
        "id": "qIxm93zNoTHj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_fashionmnist = MiniVGG()\n",
        "model_fashionmnist.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer_fashionmnist = optim.SGD(model_fashionmnist.parameters(), lr=learning_rate, momentum=momentum)\n",
        "\n",
        "train_model(model_fashionmnist, optimizer_fashionmnist, train_loader)\n",
        "\n",
        "accuracy_fashionmnist = evaluate_model(model_fashionmnist, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TB0tNw3CkDHo",
        "outputId": "b20de3a3-be64-40bc-ec40-f73c130930c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 - Loss: 2.292074187478023\n",
            "Epoch 2 - Loss: 1.0408521668870312\n",
            "Epoch 3 - Loss: 0.6004810636358728\n",
            "Epoch 4 - Loss: 0.5053610619165496\n",
            "Epoch 5 - Loss: 0.45080493185629467\n",
            "Accuracy on the test set: 83.46\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model pretrain CIFAR-10 cho kết quả cao nhất vì tính chất của các ảnh thuộc CIFAR-10 và FASHIONMNIST (đồ vật, con vật, thiên về các đường nét đa dạng, phức tạp) có độ tương đồng cao hơn so với MNIST chỉ là các con số."
      ],
      "metadata": {
        "id": "FtF5Q98Wn7SZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Extraction"
      ],
      "metadata": {
        "id": "4SW-VsGXpxER"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.models.feature_extraction import get_graph_node_names\n",
        "from torchvision.models.feature_extraction import create_feature_extractor\n",
        "\n",
        "train_nodes, eval_nodes = get_graph_node_names(model_fashionmnist)"
      ],
      "metadata": {
        "id": "_yYcp_M9pwrx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_nodes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFgQ6JJ6pwoX",
        "outputId": "72c4982d-206c-4fcb-bc29-3a01dfbfc74f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['x',\n",
              " 'features.0',\n",
              " 'features.1',\n",
              " 'features.2',\n",
              " 'features.3',\n",
              " 'features.4',\n",
              " 'features.5',\n",
              " 'features.6',\n",
              " 'features.7',\n",
              " 'features.8',\n",
              " 'features.9',\n",
              " 'features.10',\n",
              " 'features.11',\n",
              " 'features.12',\n",
              " 'features.13',\n",
              " 'features.14',\n",
              " 'flatten',\n",
              " 'classifier']"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "create_feature_extractor(model_fashionmnist, train_return_nodes= train_nodes, eval_return_nodes= eval_nodes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EzYEzmAvpwls",
        "outputId": "643d9fb5-828d-402b-d99c-cc4fdda84add"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MiniVGG(\n",
              "  (features): Module(\n",
              "    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (6): ReLU(inplace=True)\n",
              "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (8): ReLU(inplace=True)\n",
              "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (13): ReLU(inplace=True)\n",
              "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (classifier): Linear(in_features=2304, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_fashionmnist.features[0].weight"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCzs4DpipwjZ",
        "outputId": "bc84efad-05ee-4173-b808-c6c61e98cadf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[[[ 1.7197e-01,  8.4022e-02, -2.2031e-01],\n",
              "          [-2.0753e-01, -6.4311e-02,  2.8501e-01],\n",
              "          [ 2.3773e-01,  2.6604e-01, -2.9772e-01]]],\n",
              "\n",
              "\n",
              "        [[[-2.9456e-01,  2.5813e-01, -3.0895e-01],\n",
              "          [ 2.5113e-01, -2.5110e-01, -1.9612e-01],\n",
              "          [ 1.0672e-01, -2.8410e-01,  9.8710e-02]]],\n",
              "\n",
              "\n",
              "        [[[-1.9519e-01,  2.8709e-01,  2.1346e-01],\n",
              "          [-2.3781e-01, -1.3502e-01, -2.9352e-01],\n",
              "          [ 1.5684e-01,  2.1149e-01,  2.2501e-01]]],\n",
              "\n",
              "\n",
              "        [[[-2.8035e-01,  2.2753e-01, -1.2211e-02],\n",
              "          [-8.1250e-02,  2.0683e-01, -6.6967e-02],\n",
              "          [-2.5064e-01,  2.5617e-01,  2.4382e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 1.0010e-01, -1.4914e-01,  3.1136e-01],\n",
              "          [ 3.0568e-01,  2.6047e-01, -2.7086e-01],\n",
              "          [ 2.2416e-01,  1.8952e-01, -2.4795e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 1.8780e-01, -1.7215e-01, -1.3949e-01],\n",
              "          [ 2.5965e-01, -7.9825e-02, -2.5835e-01],\n",
              "          [ 1.8798e-01, -2.1342e-01, -2.2483e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 3.1954e-01,  6.1459e-02, -2.4191e-02],\n",
              "          [-3.0710e-01, -2.7834e-01,  2.6137e-01],\n",
              "          [ 2.4771e-01, -1.4268e-01,  1.8991e-01]]],\n",
              "\n",
              "\n",
              "        [[[-1.3713e-01,  3.4154e-02,  5.9261e-02],\n",
              "          [ 2.8615e-01, -5.5266e-02,  1.6439e-01],\n",
              "          [ 1.5270e-01,  2.7448e-01, -2.6700e-01]]],\n",
              "\n",
              "\n",
              "        [[[-2.4336e-01, -8.3280e-02, -8.6302e-03],\n",
              "          [ 1.7129e-02,  1.9726e-01,  2.3369e-01],\n",
              "          [-2.3020e-01,  1.5688e-01, -9.1226e-02]]],\n",
              "\n",
              "\n",
              "        [[[ 2.7412e-01, -2.9872e-01,  6.5188e-02],\n",
              "          [-5.8414e-02, -1.6315e-01, -2.8432e-01],\n",
              "          [ 1.6901e-01, -2.9937e-01, -2.6966e-02]]],\n",
              "\n",
              "\n",
              "        [[[-1.1883e-01,  9.2076e-02,  1.1881e-01],\n",
              "          [-1.4742e-01, -3.1034e-01, -2.1856e-01],\n",
              "          [ 3.1976e-02,  1.1132e-01, -4.5373e-02]]],\n",
              "\n",
              "\n",
              "        [[[ 1.4756e-01,  1.8609e-01,  1.1684e-01],\n",
              "          [ 9.9980e-02,  1.9776e-01, -1.6333e-01],\n",
              "          [-1.3237e-01, -1.5916e-01, -3.3099e-01]]],\n",
              "\n",
              "\n",
              "        [[[-2.2530e-01,  3.0155e-01,  2.9438e-01],\n",
              "          [-1.8650e-01, -5.4501e-02, -4.3642e-02],\n",
              "          [-1.4735e-01, -2.7277e-01, -1.9163e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 2.9987e-01, -2.1404e-01,  8.6331e-02],\n",
              "          [ 2.2982e-01,  2.4570e-01,  2.2525e-02],\n",
              "          [-9.1547e-02,  1.5084e-01,  2.3444e-02]]],\n",
              "\n",
              "\n",
              "        [[[-5.2252e-03, -2.8190e-02, -1.6342e-01],\n",
              "          [-2.8845e-01,  3.7550e-02,  1.2583e-01],\n",
              "          [ 1.7255e-01,  1.1647e-01,  2.9213e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 1.3984e-01,  2.0890e-01,  1.4301e-02],\n",
              "          [ 1.0530e-01,  3.0575e-01,  1.9344e-01],\n",
              "          [ 1.7917e-01,  1.0511e-01, -2.9395e-01]]],\n",
              "\n",
              "\n",
              "        [[[-1.2777e-01,  2.0442e-01,  1.9731e-01],\n",
              "          [-1.9743e-01, -1.4032e-01,  7.9744e-02],\n",
              "          [-2.0558e-01, -1.8938e-01, -2.4931e-02]]],\n",
              "\n",
              "\n",
              "        [[[-5.0645e-02,  9.6185e-02,  2.4272e-01],\n",
              "          [-2.7495e-01, -2.9834e-01, -5.1790e-02],\n",
              "          [ 1.9837e-03, -7.7573e-02,  2.0394e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 1.6291e-01,  1.1715e-01, -1.7246e-01],\n",
              "          [-2.8872e-02, -3.2811e-01, -1.5709e-01],\n",
              "          [-1.5157e-01,  1.1103e-01,  2.6669e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 2.6662e-01,  1.3161e-01, -1.1678e-01],\n",
              "          [-6.0220e-03, -3.1363e-01,  3.6124e-02],\n",
              "          [-1.3884e-01,  1.8066e-01,  2.5964e-01]]],\n",
              "\n",
              "\n",
              "        [[[-1.6372e-01,  7.6424e-02, -9.5218e-02],\n",
              "          [-2.0953e-01,  4.2976e-02, -1.0254e-01],\n",
              "          [ 9.4589e-02, -1.3351e-01, -1.1395e-01]]],\n",
              "\n",
              "\n",
              "        [[[-3.0808e-01, -1.2627e-01, -1.8963e-01],\n",
              "          [-2.3972e-01,  4.8183e-02, -1.1973e-01],\n",
              "          [ 5.1276e-02, -1.3361e-01, -5.7408e-02]]],\n",
              "\n",
              "\n",
              "        [[[ 2.5524e-01,  2.2258e-01, -3.0595e-01],\n",
              "          [-1.7698e-01,  7.9316e-02, -2.6632e-01],\n",
              "          [ 1.4072e-02,  2.6645e-01,  1.0089e-01]]],\n",
              "\n",
              "\n",
              "        [[[-7.1312e-02,  3.3164e-01,  6.6320e-02],\n",
              "          [-1.3609e-01, -2.6797e-01,  3.2692e-01],\n",
              "          [ 3.2008e-01, -8.2939e-02, -3.1608e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 2.8318e-01, -2.6647e-01,  2.5054e-01],\n",
              "          [ 2.3007e-01, -3.0611e-02,  1.2460e-01],\n",
              "          [ 3.0004e-01, -3.3342e-01,  1.5695e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 2.2245e-01,  2.8838e-01, -1.7297e-01],\n",
              "          [ 2.2238e-01, -2.3496e-01, -2.2748e-01],\n",
              "          [-9.8649e-02,  2.8214e-01, -3.0093e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 2.9916e-01, -1.5658e-01,  1.7735e-01],\n",
              "          [-3.0579e-01,  3.0621e-01, -2.3487e-01],\n",
              "          [ 1.4827e-01,  1.0996e-01,  2.1908e-01]]],\n",
              "\n",
              "\n",
              "        [[[-8.7451e-02, -2.7137e-01,  3.0520e-01],\n",
              "          [ 2.3386e-01, -1.9542e-01, -5.9454e-03],\n",
              "          [ 2.5571e-01,  2.2952e-01, -3.5733e-02]]],\n",
              "\n",
              "\n",
              "        [[[ 6.1118e-02, -2.2231e-01,  4.6313e-02],\n",
              "          [ 5.3121e-02,  2.3509e-01,  2.4561e-01],\n",
              "          [ 4.1397e-02, -1.1373e-01, -2.7790e-01]]],\n",
              "\n",
              "\n",
              "        [[[-3.3150e-01,  1.0738e-01, -1.2957e-01],\n",
              "          [-4.8745e-02, -7.6134e-02,  1.7165e-01],\n",
              "          [ 1.5624e-01,  1.1128e-01,  1.2337e-02]]],\n",
              "\n",
              "\n",
              "        [[[-3.1534e-01,  3.0286e-01,  1.4884e-02],\n",
              "          [-3.3314e-01,  1.2260e-01, -2.8196e-01],\n",
              "          [-1.0160e-01,  2.8300e-01, -8.0837e-03]]],\n",
              "\n",
              "\n",
              "        [[[ 3.1951e-01,  4.3966e-02, -4.5172e-03],\n",
              "          [ 5.9641e-02,  2.1672e-01, -2.4688e-01],\n",
              "          [ 2.0190e-01, -8.0320e-02,  2.1620e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 2.9357e-01, -7.8573e-02,  1.3995e-01],\n",
              "          [-2.0094e-01,  1.5707e-01,  1.6857e-01],\n",
              "          [ 2.3284e-01, -2.6737e-01, -2.3817e-01]]],\n",
              "\n",
              "\n",
              "        [[[-2.4492e-01,  3.1332e-01,  5.7991e-02],\n",
              "          [-1.5173e-01, -1.5455e-01, -5.6956e-02],\n",
              "          [-7.6865e-02, -1.4704e-01, -3.0077e-01]]],\n",
              "\n",
              "\n",
              "        [[[-7.8045e-02, -1.4201e-01, -2.0294e-01],\n",
              "          [ 2.0397e-01,  2.4444e-01,  2.4467e-01],\n",
              "          [-5.3980e-02, -2.3902e-01,  2.2938e-01]]],\n",
              "\n",
              "\n",
              "        [[[-1.0008e-01, -5.9978e-02,  7.1196e-02],\n",
              "          [ 1.8389e-01,  3.0107e-01,  2.7352e-01],\n",
              "          [ 7.7851e-02,  2.2583e-02, -1.1085e-01]]],\n",
              "\n",
              "\n",
              "        [[[-2.5508e-01, -2.4021e-03, -4.3942e-02],\n",
              "          [ 1.5692e-01,  9.2141e-02,  3.3036e-02],\n",
              "          [ 3.2387e-01,  1.6198e-01,  1.1952e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 6.5162e-02, -2.9900e-01, -3.0532e-01],\n",
              "          [ 2.1762e-01,  1.8760e-01,  3.2396e-02],\n",
              "          [ 1.8059e-01, -3.2525e-01, -1.5176e-01]]],\n",
              "\n",
              "\n",
              "        [[[-3.2900e-01, -4.7616e-02, -1.9584e-01],\n",
              "          [ 1.7133e-01, -1.3183e-01,  2.3893e-01],\n",
              "          [-2.0606e-01, -2.9574e-01, -2.3072e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 2.0282e-01,  2.7269e-01, -2.4375e-01],\n",
              "          [-3.2276e-02, -1.1766e-01, -2.6011e-01],\n",
              "          [ 1.1795e-02,  1.0726e-01,  1.1524e-01]]],\n",
              "\n",
              "\n",
              "        [[[-8.0965e-02, -2.8841e-01,  1.1367e-01],\n",
              "          [ 2.5426e-01,  2.5351e-01, -2.9083e-01],\n",
              "          [ 1.5590e-01, -2.1882e-03,  3.2170e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 2.7980e-01,  1.4803e-01, -1.0593e-01],\n",
              "          [ 2.7484e-01,  1.8328e-01,  2.9007e-02],\n",
              "          [-1.9220e-01,  2.1025e-01,  2.4558e-01]]],\n",
              "\n",
              "\n",
              "        [[[-1.3504e-01, -1.9958e-01, -9.7467e-02],\n",
              "          [ 1.4149e-01, -6.2036e-02,  9.5293e-02],\n",
              "          [ 4.4953e-02, -2.4318e-01, -9.1004e-02]]],\n",
              "\n",
              "\n",
              "        [[[-2.1513e-01, -2.0263e-01,  1.5605e-01],\n",
              "          [ 1.1522e-01,  1.4165e-01,  7.0091e-02],\n",
              "          [ 6.5952e-02, -1.0489e-01, -7.0195e-02]]],\n",
              "\n",
              "\n",
              "        [[[ 2.5608e-01, -3.2231e-01, -1.3417e-01],\n",
              "          [-3.2899e-02, -5.0487e-03,  2.1762e-02],\n",
              "          [-2.2804e-01,  1.8178e-01, -1.7258e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 1.2754e-01,  1.3568e-01,  6.9100e-02],\n",
              "          [-2.3861e-01,  2.7075e-01, -1.2628e-01],\n",
              "          [ 2.6111e-01, -1.0577e-01,  3.0377e-01]]],\n",
              "\n",
              "\n",
              "        [[[-7.0905e-02, -1.7834e-01,  9.6255e-02],\n",
              "          [ 2.0721e-01,  1.5971e-01,  2.4133e-01],\n",
              "          [-1.6838e-01,  1.1378e-02, -4.4062e-02]]],\n",
              "\n",
              "\n",
              "        [[[ 7.4647e-02, -3.3308e-01, -4.1234e-02],\n",
              "          [ 2.3863e-01, -3.8770e-02,  1.8637e-01],\n",
              "          [ 1.4227e-01,  5.1468e-02, -3.1451e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 8.2050e-02, -1.0732e-01,  1.8955e-01],\n",
              "          [-1.9285e-01, -2.1869e-02, -1.4676e-01],\n",
              "          [ 2.1761e-01, -3.3336e-01, -1.0746e-01]]],\n",
              "\n",
              "\n",
              "        [[[-2.2158e-01,  2.6024e-01,  2.9712e-01],\n",
              "          [-4.7430e-02,  3.2177e-01,  1.3769e-01],\n",
              "          [ 2.2241e-01, -2.7306e-01,  3.6638e-02]]],\n",
              "\n",
              "\n",
              "        [[[-1.9611e-01,  1.6333e-01,  4.2363e-02],\n",
              "          [ 1.2816e-01, -1.5898e-01,  9.9991e-02],\n",
              "          [ 2.2893e-01, -1.7435e-01, -1.6884e-01]]],\n",
              "\n",
              "\n",
              "        [[[-1.9527e-01,  2.6901e-04, -2.9404e-01],\n",
              "          [-1.7891e-01,  9.4217e-02, -2.8281e-02],\n",
              "          [-2.7853e-01,  1.2844e-01,  2.2895e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 2.0003e-01,  1.2799e-01,  2.1258e-01],\n",
              "          [-2.7941e-01,  9.8355e-02,  1.5342e-01],\n",
              "          [-4.8962e-02, -2.2878e-01, -3.1136e-01]]],\n",
              "\n",
              "\n",
              "        [[[-1.1677e-01,  1.2369e-01,  2.8551e-01],\n",
              "          [-3.5613e-02, -9.1315e-02,  1.7934e-01],\n",
              "          [ 2.9572e-01, -2.7133e-01,  6.3064e-02]]],\n",
              "\n",
              "\n",
              "        [[[-3.2734e-01,  6.4809e-04, -1.8415e-01],\n",
              "          [ 2.4923e-01,  2.2996e-01, -3.1931e-01],\n",
              "          [-2.7850e-01,  1.4273e-01,  2.7205e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 2.5265e-01, -4.1591e-02, -1.2606e-01],\n",
              "          [-1.4099e-01, -4.1446e-02, -4.8813e-02],\n",
              "          [ 2.9639e-01, -2.9057e-01, -2.4118e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 6.1613e-02,  2.8186e-01, -6.6539e-02],\n",
              "          [ 1.5299e-01,  1.4157e-01,  1.6888e-01],\n",
              "          [ 8.4580e-03,  1.6015e-01,  3.3026e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 1.5874e-01, -2.5063e-01, -4.7280e-02],\n",
              "          [-2.1882e-01, -3.1198e-01,  1.8970e-01],\n",
              "          [-2.0789e-01,  2.0341e-01,  2.9593e-01]]],\n",
              "\n",
              "\n",
              "        [[[-9.8206e-02, -6.6129e-02,  6.1873e-02],\n",
              "          [-1.6945e-01, -1.0898e-02, -2.2331e-01],\n",
              "          [ 1.1257e-02, -2.0077e-01, -6.7585e-02]]],\n",
              "\n",
              "\n",
              "        [[[-2.4257e-01, -6.8974e-02, -1.5463e-03],\n",
              "          [-2.0777e-01, -2.8143e-02,  1.0372e-01],\n",
              "          [-5.8163e-02,  1.7629e-01,  2.2081e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 4.2589e-02, -1.7513e-01, -2.7288e-01],\n",
              "          [-1.0487e-01,  8.8902e-02,  1.6107e-01],\n",
              "          [-1.7938e-01, -1.4135e-01, -2.5141e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 1.1622e-01, -2.8021e-01, -2.5019e-01],\n",
              "          [ 1.4088e-01,  2.1441e-01, -1.1956e-01],\n",
              "          [ 1.3613e-01, -7.1402e-02, -2.2100e-01]]],\n",
              "\n",
              "\n",
              "        [[[-1.3364e-01,  2.6201e-02,  2.3494e-02],\n",
              "          [-3.8717e-03,  2.4111e-01, -7.0311e-02],\n",
              "          [ 2.4611e-01, -5.3939e-02,  2.2891e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 3.2714e-01,  1.3455e-01, -5.0290e-02],\n",
              "          [ 2.4826e-01,  3.2804e-02, -2.5967e-01],\n",
              "          [-1.2990e-01,  2.2669e-01, -9.8486e-02]]]], device='cuda:0',\n",
              "       requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    }
  ]
}